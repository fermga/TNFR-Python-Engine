{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da4942",
   "metadata": {},
   "source": [
    "# TNFR Periodic Table Atlas (Z=1..10)\n",
    "\n",
    "This notebook builds element-like radial graphs using TNFR helpers, computes the Structural Field Tetrad (Φ_s, |∇φ|, K_φ, ξ_C), runs a sequential U6 (ΔΦ_s) check, and exports an HTML table mirroring the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3794d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "from tnfr.examples_utils import build_element_radial_graph, apply_synthetic_activation_sequence\n",
    "from tnfr.physics.fields import (\n",
    "    compute_structural_potential, compute_phase_gradient, compute_phase_curvature, estimate_coherence_length\n",
    ")\n",
    "from tnfr.operators.grammar import (\n",
    "    warn_phase_gradient_telemetry, warn_phase_curvature_telemetry, warn_coherence_length_telemetry, validate_structural_potential_confinement\n",
    ")\n",
    "from tnfr.telemetry.constants import (\n",
    "    PHASE_GRADIENT_THRESHOLD, PHASE_CURVATURE_ABS_THRESHOLD, STRUCTURAL_POTENTIAL_DELTA_THRESHOLD\n",
    ")\n",
    "from importlib import import_module\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "periodic_mod = import_module('examples.periodic_table_atlas')  # reuse render_html and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c58a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze elements Z=1..10 and display a DataFrame\n",
    "rows = []\n",
    "for Z in range(1, 11):\n",
    "    G = build_element_radial_graph(Z, seed=42)\n",
    "    phi_before = compute_structural_potential(G)\n",
    "    grad = compute_phase_gradient(G)\n",
    "    kphi = compute_phase_curvature(G)\n",
    "    xi_c = float(estimate_coherence_length(G))\n",
    "    _, stats_g, msg_g, _ = warn_phase_gradient_telemetry(G, threshold=PHASE_GRADIENT_THRESHOLD)\n",
    "    _, stats_k, msg_k, _ = warn_phase_curvature_telemetry(G, abs_threshold=PHASE_CURVATURE_ABS_THRESHOLD, multiscale_check=True, alpha_hint=2.76)\n",
    "    _, stats_x, msg_x = warn_coherence_length_telemetry(G)\n",
    "    apply_synthetic_activation_sequence(G, alpha=0.25, dnfr_factor=0.9)\n",
    "    phi_after = compute_structural_potential(G)\n",
    "    ok, drift, msg_u6 = validate_structural_potential_confinement(G, phi_before, phi_after, threshold=STRUCTURAL_POTENTIAL_DELTA_THRESHOLD, strict=False)\n",
    "    total = max(1, len(G.nodes()))\n",
    "    local_count = sum(\n",
    "        1 for n in G.nodes()\n",
    "        if abs(float(grad.get(n, 0.0))) < PHASE_GRADIENT_THRESHOLD and abs(float(kphi.get(n, 0.0))) < PHASE_CURVATURE_ABS_THRESHOLD\n",
    ")\n",
    "    rows.append({\n",
    "        'Z': Z,\n",
    "        'symbol': periodic_mod.SYMBOLS.get(Z, str(Z)),\n",
    "        'xi_c': xi_c,\n",
    "        'mean_grad': float(stats_g.get('mean_abs', 0.0)),\n",
    "        'mean_kphi': float(stats_k.get('mean_abs', 0.0)),\n",
    "        'mean_path_length': float(stats_x.get('mean_path_length', 0.0)),\n",
    "        'local_frac': float(local_count) / float(total),\n",
    "        'u6_ok': bool(ok),\n",
    "        'u6_drift': float(drift),\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML parity with the script\n",
    "base = os.path.join(os.path.dirname(periodic_mod.__file__), 'output')\n",
    "out_html = os.path.join(base, 'periodic_table_atlas.html')\n",
    "periodic_mod.render_html(rows, out_path=out_html)\n",
    "print('Wrote periodic table atlas to:', out_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05251ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: JSONL/CSV exports to mirror the script outputs\n",
    "out_jsonl = os.path.join(base, 'periodic_table_atlas.jsonl')\n",
    "out_csv = os.path.join(base, 'periodic_table_atlas.csv')\n",
    "# Reuse internal helpers if present; fallback to simple writers\n",
    "try:\n",
    "    periodic_mod._write_jsonl(rows, out_jsonl)\n",
    "    periodic_mod._write_csv(rows, out_csv)\n",
    "except Exception:\n",
    "    import json\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "    with open(out_jsonl, 'w', encoding='utf-8') as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "    import csv\n",
    "    with open(out_csv, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['Z','symbol','xi_c','mean_grad','mean_kphi','mean_path_length','local_frac','u6_ok','u6_drift'])\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow({k: r.get(k) for k in writer.fieldnames})\n",
    "print('Exported JSONL and CSV to:', base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by Signature (telemetry-only)\n",
    "# This cell mirrors the HTML/CSV summary produced by examples/periodic_table_atlas.py\n",
    "# It does not change operator dynamics; it only aggregates telemetry.\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "\n",
    "# Try to source rows from existing variables\n",
    "rows_data = None\n",
    "try:\n",
    "    if isinstance(rows, list) and rows and isinstance(rows[0], dict):\n",
    "        rows_data = rows\n",
    "except NameError:\n",
    "    rows_data = None\n",
    "\n",
    "if rows_data is None:\n",
    "    try:\n",
    "        # Attempt to reconstruct from a DataFrame named df, if present\n",
    "        if 'df' in globals():\n",
    "            rows_data = [\n",
    "                {\n",
    "                    'signature': rec.get('signature', ''),\n",
    "                    'u6_ok': bool(rec.get('u6_ok', False)),\n",
    "                    'xi_c': float(rec.get('xi_c', 0.0)),\n",
    "                    'mean_grad': float(rec.get('mean_grad', 0.0)),\n",
    "                    'mean_kphi': float(rec.get('mean_kphi', 0.0)),\n",
    "                    'local_frac': float(rec.get('local_frac', 0.0)),\n",
    "                }\n",
    "                for rec in df.to_dict(orient='records')\n",
    "            ]\n",
    "    except Exception as e:\n",
    "        print('Could not reconstruct rows from df:', e)\n",
    "        rows_data = None\n",
    "\n",
    "if not rows_data:\n",
    "    print('No telemetry rows found. Run the earlier cells that build rows/df first.')\n",
    "else:\n",
    "    groups = defaultdict(list)\n",
    "    for r in rows_data:\n",
    "        groups[str(r.get('signature', ''))].append(r)\n",
    "\n",
    "    def safe_mean(vals):\n",
    "        return float(mean(vals)) if vals else 0.0\n",
    "\n",
    "    summary_records = []\n",
    "    total = sum(len(v) for v in groups.values()) or 1\n",
    "    dist_records = []\n",
    "\n",
    "    for sig, items in groups.items():\n",
    "        cnt = len(items)\n",
    "        pass_rate = safe_mean([1.0 if it.get('u6_ok', False) else 0.0 for it in items])\n",
    "        mean_xi = safe_mean([float(it.get('xi_c', 0.0)) for it in items])\n",
    "        mean_g = safe_mean([float(it.get('mean_grad', 0.0)) for it in items])\n",
    "        mean_k = safe_mean([float(it.get('mean_kphi', 0.0)) for it in items])\n",
    "        mean_loc = safe_mean([float(it.get('local_frac', 0.0)) for it in items])\n",
    "        summary_records.append({\n",
    "            'signature': sig,\n",
    "            'count': cnt,\n",
    "            'pass_rate': pass_rate,\n",
    "            'mean_xi_c': mean_xi,\n",
    "            'mean_grad': mean_g,\n",
    "            'mean_kphi': mean_k,\n",
    "            'mean_local_frac': mean_loc,\n",
    "        })\n",
    "        dist_records.append({'signature': sig, 'count': cnt, 'pct': 100.0 * cnt / float(total)})\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_records).sort_values(by=['signature']).reset_index(drop=True)\n",
    "    dist_df = pd.DataFrame(dist_records).sort_values(by=['signature']).reset_index(drop=True)\n",
    "\n",
    "    display(summary_df)\n",
    "    display(dist_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Summary by Signature to disk (parity with script outputs)\n",
    "# Writes:\n",
    "# - examples/output/periodic_table_atlas_by_signature.csv\n",
    "# - examples/output/periodic_table_atlas_summary.json\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Reuse summary_df/dist_df if present; else try to rebuild via the previous logic\n",
    "try:\n",
    "    have_summary = 'summary_df' in globals() and 'dist_df' in globals()\n",
    "except Exception:\n",
    "    have_summary = False\n",
    "\n",
    "if not have_summary:\n",
    "    # Attempt minimal rebuild using the same approach as previous cell\n",
    "    from collections import defaultdict\n",
    "    from statistics import mean\n",
    "    rows_data = None\n",
    "    try:\n",
    "        if isinstance(rows, list) and rows and isinstance(rows[0], dict):\n",
    "            rows_data = rows\n",
    "    except NameError:\n",
    "        rows_data = None\n",
    "    if rows_data is None and 'df' in globals():\n",
    "        rows_data = [\n",
    "            {\n",
    "                'signature': rec.get('signature', ''),\n",
    "                'u6_ok': bool(rec.get('u6_ok', False)),\n",
    "                'xi_c': float(rec.get('xi_c', 0.0)),\n",
    "                'mean_grad': float(rec.get('mean_grad', 0.0)),\n",
    "                'mean_kphi': float(rec.get('mean_kphi', 0.0)),\n",
    "                'local_frac': float(rec.get('local_frac', 0.0)),\n",
    "            }\n",
    "            for rec in df.to_dict(orient='records')\n",
    "        ]\n",
    "    if not rows_data:\n",
    "        print('No telemetry rows found. Run the earlier cells first.')\n",
    "    else:\n",
    "        groups = defaultdict(list)\n",
    "        for r in rows_data:\n",
    "            groups[str(r.get('signature', ''))].append(r)\n",
    "        def safe_mean(vals):\n",
    "            return float(mean(vals)) if vals else 0.0\n",
    "        summary_records = []\n",
    "        for sig, items in groups.items():\n",
    "            summary_records.append({\n",
    "                'signature': sig,\n",
    "                'count': len(items),\n",
    "                'pass_rate': safe_mean([1.0 if it.get('u6_ok', False) else 0.0 for it in items]),\n",
    "                'mean_xi_c': safe_mean([float(it.get('xi_c', 0.0)) for it in items]),\n",
    "                'mean_grad': safe_mean([float(it.get('mean_grad', 0.0)) for it in items]),\n",
    "                'mean_kphi': safe_mean([float(it.get('mean_kphi', 0.0)) for it in items]),\n",
    "                'mean_local_frac': safe_mean([float(it.get('local_frac', 0.0)) for it in items]),\n",
    "            })\n",
    "        import pandas as pd\n",
    "        summary_df = pd.DataFrame(summary_records)\n",
    "\n",
    "if 'summary_df' not in globals():\n",
    "    print('No summary_df available; nothing to write.')\n",
    "else:\n",
    "    # Locate repo root by searching for pyproject.toml\n",
    "    def find_repo_root(start: Path) -> Path:\n",
    "        for p in [start, *start.parents]:\n",
    "            if (p / 'pyproject.toml').exists():\n",
    "                return p\n",
    "        return start\n",
    "    repo_root = find_repo_root(Path.cwd())\n",
    "    out_dir = repo_root / 'examples' / 'output'\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    groups_csv = out_dir / 'periodic_table_atlas_by_signature.csv'\n",
    "    summary_json = out_dir / 'periodic_table_atlas_summary.json'\n",
    "\n",
    "    # Write CSV\n",
    "    summary_df.to_csv(groups_csv, index=False)\n",
    "\n",
    "    # Write JSON as mapping signature -> metrics\n",
    "    summary_map = {\n",
    "        str(row['signature']): {\n",
    "            'count': float(row['count']),\n",
    "            'pass_rate': float(row['pass_rate']),\n",
    "            'mean_xi_c': float(row['mean_xi_c']),\n",
    "            'mean_grad': float(row['mean_grad']),\n",
    "            'mean_kphi': float(row['mean_kphi']),\n",
    "            'mean_local_frac': float(row['mean_local_frac']),\n",
    "        }\n",
    "        for _, row in summary_df.fillna(0.0).iterrows()\n",
    "    }\n",
    "    with open(summary_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary_map, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print('Wrote:', groups_csv)\n",
    "    print('Wrote:', summary_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
