{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcdc8f6",
   "metadata": {},
   "source": [
    "# TNFR Structural Field Tetrad: End-to-End Exploration\n",
    "This notebook explores the four CANONICAL TNFR structural fields (Φ_s, |∇φ|, K_φ, ξ_C) and related research utilities on multiple graph topologies, using the implementation in this repository.\n",
    "\n",
    "Prerequisites (run in VS Code terminal, PowerShell):\n",
    "- python -m pip install --upgrade numpy networkx matplotlib scikit-learn\n",
    "\n",
    "We’ll keep dependencies light and stick to numpy, networkx, and matplotlib. If scikit-learn is missing, phase symmetry metrics will gracefully fall back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a69f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "# Set Up Environment\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"Seeds set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Project Path (VS Code workspace)\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find repo root that contains src/tnfr\n",
    "cwd = Path.cwd()\n",
    "repo_root = None\n",
    "for base in [cwd] + list(cwd.parents):\n",
    "    if (base / \"src\" / \"tnfr\").exists() or (base / \"pyproject.toml\").exists():\n",
    "        repo_root = base\n",
    "        break\n",
    "\n",
    "SRC = (repo_root / \"src\") if repo_root else (cwd / \"src\")\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "print(\"Project src set:\", SRC if SRC.exists() else \"NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and TNFR Field Functions\n",
    "import math\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tnfr.physics.fields import (\n",
    "    compute_structural_potential,\n",
    "    compute_phase_gradient,\n",
    "    compute_phase_curvature,\n",
    "    compute_k_phi_multiscale_variance,\n",
    "    fit_k_phi_asymptotic_alpha,\n",
    "    k_phi_multiscale_safety,\n",
    "    estimate_coherence_length,\n",
    "    fit_correlation_length_exponent,\n",
    "    measure_phase_symmetry,\n",
    "    path_integrated_gradient,\n",
    " )\n",
    "print(\"Imports OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Benchmark Graphs (ring, WS, scale-free, grid, tree)\n",
    "def make_graphs(n=60, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    graphs = {}\n",
    "    graphs['ring'] = nx.cycle_graph(n)\n",
    "    graphs['ws'] = nx.watts_strogatz_graph(n, k=min(4, n-1), p=0.2, seed=seed)\n",
    "    # Use Barabasi-Albert for scale-free (undirected)\n",
    "    graphs['scale_free'] = nx.barabasi_albert_graph(n, m=2, seed=seed)\n",
    "    # Grid: relabel to 0..N-1\n",
    "    side = max(2, int(math.sqrt(n)))\n",
    "    Ggrid = nx.grid_2d_graph(side, side)\n",
    "    mapping = {node: i for i, node in enumerate(Ggrid.nodes())}\n",
    "    graphs['grid'] = nx.relabel_nodes(Ggrid, mapping)\n",
    "    # Tree: balanced binary with ~n nodes\n",
    "    h = max(1, int(math.log2(n)))\n",
    "    Gtree = nx.balanced_tree(r=2, h=h)\n",
    "    if Gtree.number_of_nodes() > n:\n",
    "        nodes_to_remove = list(Gtree.nodes())[n:]\n",
    "        Gtree.remove_nodes_from(nodes_to_remove)\n",
    "    graphs['tree'] = Gtree\n",
    "    return graphs\n",
    "graphs = make_graphs(n=60, seed=42)\n",
    "print(\"Graphs:\", {k: (v.number_of_nodes(), v.number_of_edges()) for k,v in graphs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45477241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Node Telemetry (θ, ΔNFR, coherence)\n",
    "def init_telemetry(G, seed=123, grad_bias=0.2):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # random base phases in [0, 2π)\n",
    "    base = rng.uniform(0.0, 2*math.pi, size=G.number_of_nodes())\n",
    "    # Introduce mild structured gradient by projecting node index\n",
    "    nodes = list(G.nodes())\n",
    "    for idx, n in enumerate(nodes):\n",
    "        theta = (base[idx] + grad_bias * (idx / max(1, len(nodes)-1))) % (2*math.pi)\n",
    "        delta_nfr = float(rng.uniform(0.05, 0.2))\n",
    "        G.nodes[n]['theta'] = float(theta)\n",
    "        G.nodes[n]['phase'] = float(theta)  # alias\n",
    "        G.nodes[n]['delta_nfr'] = delta_nfr\n",
    "        G.nodes[n]['dnfr'] = delta_nfr\n",
    "        G.nodes[n]['coherence'] = 1.0 / (1.0 + abs(delta_nfr))\n",
    "for name, G in graphs.items():\n",
    "    init_telemetry(G, seed=100 + hash(name)%1000, grad_bias=0.4)\n",
    "print(\"Telemetry initialized: theta, delta_nfr, coherence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1059f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Structural Potential Φ_s and drift check\n",
    "def phi_s_and_drift(G):\n",
    "    phi_before = compute_structural_potential(G, alpha=2.0)\n",
    "    # Benign perturbation: small uniform delta_nfr tweak\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['delta_nfr'] = float(G.nodes[n]['delta_nfr'] * 1.01)\n",
    "        G.nodes[n]['dnfr'] = float(G.nodes[n]['dnfr'] * 1.01)\n",
    "    phi_after = compute_structural_potential(G, alpha=2.0)\n",
    "    nodes = list(G.nodes())\n",
    "    if nodes:\n",
    "        drift = float(np.mean([abs(phi_after[n] - phi_before[n]) for n in nodes]))\n",
    "    else:\n",
    "        drift = 0.0\n",
    "    return phi_before, phi_after, drift\n",
    "for name, G in graphs.items():\n",
    "    phi_b, phi_a, drift = phi_s_and_drift(G)\n",
    "    print(f\"{name:10s} ΔΦ_s (mean drift): {drift:.4f}  (threshold 2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870836bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Phase Gradient |∇φ| and flag risky nodes (|∇φ| ≥ 0.38)\n",
    "grad_maps = {}\n",
    "for name, G in graphs.items():\n",
    "    grad = compute_phase_gradient(G)\n",
    "    grad_maps[name] = grad\n",
    "    vals = np.array(list(grad.values())) if grad else np.array([])\n",
    "    risky = int(np.sum(vals >= 0.38)) if vals.size else 0\n",
    "    print(f\"{name:10s} |∇φ| mean={vals.mean():.4f} risky_nodes={risky}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Phase Curvature K_φ and hotspots (|K_φ| ≥ 3.0)\n",
    "kphi_maps = {}\n",
    "for name, G in graphs.items():\n",
    "    kphi = compute_phase_curvature(G)\n",
    "    kphi_maps[name] = kphi\n",
    "    absmax = float(np.max(np.abs(list(kphi.values())))) if kphi else 0.0\n",
    "    hotspots = sum(1 for v in kphi.values() if abs(v) >= 3.0) if kphi else 0\n",
    "    print(f\"{name:10s} |K_φ|_max={absmax:.3f} hotspots={hotspots}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiscale K_φ Variance and α fit\n",
    "for name, G in graphs.items():\n",
    "    var_by_scale = compute_k_phi_multiscale_variance(G, scales=(1,2,3,5))\n",
    "    fit = fit_k_phi_asymptotic_alpha(var_by_scale)\n",
    "    print(f\"{name:10s} scales={list(var_by_scale.keys())} α={fit['alpha']:.3f} R²={fit['r_squared']:.3f} ({fit['fit_quality']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03cbcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiscale Curvature Safety Check (α_hint=2.76, tolerance=2.0)\n",
    "for name, G in graphs.items():\n",
    "    safety = k_phi_multiscale_safety(G, scales=(1,2,3,5), alpha_hint=2.76, tolerance_factor=2.0, fit_min_r2=0.5)\n",
    "    print(f\"{name:10s} safe={safety['safe']} violations={safety['violations']} R²={safety['fit'].get('r_squared',0.0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c55142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Coherence Length ξ_C via Radial Decay\n",
    "for name, G in graphs.items():\n",
    "    xi = estimate_coherence_length(G, coherence_key='coherence')\n",
    "    print(f\"{name:10s} ξ_C ≈ {xi:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf38865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep intensity I around I_c and fit ν for ξ_C ~ |I - I_c|^{-ν}\n",
    "I_c = 2.015\n",
    "rng = np.random.default_rng(7)\n",
    "Is = np.array([1.6, 1.8, 1.9, 2.0, 2.03, 2.1, 2.3, 2.5], dtype=float)\n",
    "xi_vals = []\n",
    "# Use the WS graph as representative for the sweep\n",
    "G_ws = graphs['ws'].copy()\n",
    "for I in Is:\n",
    "    # Perturb ΔNFR magnitude to emulate regime intensity\n",
    "    scale = 1.0 + (I - I_c) * 0.5\n",
    "    for n in G_ws.nodes():\n",
    "        base = float(G_ws.nodes[n]['delta_nfr'])\n",
    "        G_ws.nodes[n]['delta_nfr'] = abs(base * scale)\n",
    "        G_ws.nodes[n]['dnfr'] = abs(base * scale)\n",
    "    xi_vals.append(estimate_coherence_length(G_ws, coherence_key='coherence'))\n",
    "xi_vals = np.array(xi_vals, dtype=float)\n",
    "fit_res = fit_correlation_length_exponent(Is, xi_vals, I_c=I_c, min_distance=0.01)\n",
    "print(\"I:\", Is)\n",
    "print(\"xi_C:\", xi_vals)\n",
    "print({k: v for k,v in fit_res.items() if not k.startswith('n_points')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase Symmetry Metrics (clustering on unit circle)\n",
    "for name, G in graphs.items():\n",
    "    sym = measure_phase_symmetry(G)\n",
    "    print(f\"{name:10s}\", sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path-Integrated Gradient (PIG) on a shortest path\n",
    "for name, G in graphs.items():\n",
    "    nodes = list(G.nodes())\n",
    "    if len(nodes) < 2:\n",
    "        continue\n",
    "    src, dst = nodes[0], nodes[-1]\n",
    "    try:\n",
    "        path = nx.shortest_path(G, src, dst)\n",
    "    except Exception:\n",
    "        continue\n",
    "    pig = path_integrated_gradient(G, path)\n",
    "    print(f\"{name:10s} path length {len(path)} PIG={pig:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal Assertions (sanity checks, soft)\n",
    "issues = []\n",
    "for name, G in graphs.items():\n",
    "    grad = grad_maps[name]\n",
    "    kphi = kphi_maps[name]\n",
    "    # Shapes match |V|\n",
    "    if len(grad) != G.number_of_nodes() or len(kphi) != G.number_of_nodes():\n",
    "        issues.append(f\"{name}: length mismatch (grad {len(grad)}, kphi {len(kphi)}, nodes {G.number_of_nodes()})\")\n",
    "    # Non-trivial values\n",
    "    try:\n",
    "        _max_abs = float(np.max(np.abs(list(kphi.values())))) if kphi else 0.0\n",
    "    except Exception as e:\n",
    "        issues.append(f\"{name}: kphi values error: {e}\")\n",
    "        _max_abs = 0.0\n",
    "    # Multiscale variance should generally not explode with r in healthy-ish setup\n",
    "    var_by_scale = compute_k_phi_multiscale_variance(G, scales=(1,2,3))\n",
    "    vals = [var_by_scale[r] for r in sorted(var_by_scale.keys())]\n",
    "    if max(vals) > 10 * (min(vals) + 1e-9):\n",
    "        issues.append(f\"{name}: k_phi variance grows too fast across scales: {vals}\")\n",
    "    safety = k_phi_multiscale_safety(G, scales=(1,2,3,5), alpha_hint=2.76)\n",
    "    if not isinstance(safety.get('safe', None), bool):\n",
    "        issues.append(f\"{name}: safety result malformed: {safety}\")\n",
    "\n",
    "if issues:\n",
    "    print(\"WARN: Sanity checks found issues:\")\n",
    "    for it in issues:\n",
    "        print(\" -\", it)\n",
    "else:\n",
    "    print(\"Assertions passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8467c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Plots and Diagnostics\n",
    "def _tight():\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Histograms of |∇φ| and K_φ for one graph\n",
    "name = 'ws' if 'ws' in graphs else list(graphs.keys())[0]\n",
    "G = graphs[name]\n",
    "grad = np.array(list(grad_maps[name].values()))\n",
    "kphi = np.array(list(kphi_maps[name].values()))\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "axs[0].hist(grad, bins=20, color='tab:blue', alpha=0.8)\n",
    "axs[0].set_title(f\"{name} |∇φ| histogram\")\n",
    "axs[1].hist(kphi, bins=20, color='tab:orange', alpha=0.8)\n",
    "axs[1].set_title(f\"{name} K_φ histogram\")\n",
    "_tight()\n",
    "\n",
    "# Log–log var(K_φ) vs r with fitted line\n",
    "var_by_scale = compute_k_phi_multiscale_variance(G, scales=(1,2,3,5))\n",
    "fit = fit_k_phi_asymptotic_alpha(var_by_scale)\n",
    "rs = np.array(sorted(var_by_scale.keys()), dtype=float)\n",
    "vars_ = np.array([var_by_scale[int(r)] for r in rs], dtype=float)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,4))\n",
    "ax.plot(np.log(rs+1e-9), np.log(vars_+1e-12), 'o-', label='data')\n",
    "if fit['alpha'] > 0:\n",
    "    # Fit line: log(var) ~ a - alpha * log(r) (we'll reconstruct via simple linear fit)\n",
    "    # Refit here to get intercept for plotting\n",
    "    X = np.vstack([np.ones_like(np.log(rs)), -np.log(rs)]).T\n",
    "    y = np.log(vars_ + 1e-12)\n",
    "    coeffs, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    y_pred = X @ coeffs\n",
    "    ax.plot(np.log(rs+1e-9), y_pred, '-', label=f\"fit α≈{fit['alpha']:.2f}, R²≈{fit['r_squared']:.2f}\")\n",
    "ax.set_xlabel('log r')\n",
    "ax.set_ylabel('log var(K_φ)')\n",
    "ax.legend()\n",
    "_tight()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
